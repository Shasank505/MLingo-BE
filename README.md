# ğŸ® Gamified Machine Learning Learning Platform

A production-ready, gamified platform for learning Machine Learning through interactive quests, automated model evaluation, and achievement tracking.

## ğŸŒŸ Features

### Core Features
- âœ… **User Authentication** - JWT-based secure authentication
- ğŸ¯ **Quest System** - Structured ML learning path with levels and quests
- ğŸ¤– **Automated Model Evaluation** - Generic evaluation engine for any ML model
- ğŸ† **Achievements & Badges** - Earn badges based on XP, streaks, and performance
- ğŸ“Š **Leaderboard** - Global rankings by XP and completed quests
- ğŸ”¥ **Daily Streaks** - Track consecutive days of learning
- ğŸ“ˆ **Progress Tracking** - Detailed user progress and statistics

### Technical Features
- ğŸ—ï¸ **Clean Architecture** - Modular, scalable, maintainable code
- ğŸ” **Secure** - Password hashing, JWT tokens, input validation
- ğŸ“¦ **Docker Support** - Easy deployment with Docker/Docker Compose
- ğŸ“š **API Documentation** - Auto-generated with FastAPI (Swagger UI)
- ğŸ§ª **Testable** - Comprehensive test suite included

## ğŸ—ï¸ Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Client Layer                            â”‚
â”‚  (Browser, Mobile App, API Client, Streamlit Dashboard)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ HTTP/REST
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FastAPI Application                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Routes    â”‚  â”‚  Services   â”‚  â”‚  ML Engine  â”‚        â”‚
â”‚  â”‚  (API       â”‚â”€â”€â”‚  (Business  â”‚â”€â”€â”‚  (Model     â”‚        â”‚
â”‚  â”‚  Endpoints) â”‚  â”‚   Logic)    â”‚  â”‚  Evaluation)â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚         â”‚                 â”‚                                  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚                           â–¼              â–¼                  â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚                    â”‚   Models     â”‚  â”‚   Schemas    â”‚      â”‚
â”‚                    â”‚ (SQLAlchemy) â”‚  â”‚  (Pydantic)  â”‚      â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Database   â”‚
                    â”‚   (SQLite)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Directory Structure

```
ml_game_platform/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI application entry point
â”‚   â”œâ”€â”€ database.py          # Database configuration
â”‚   â”œâ”€â”€ schemas.py           # Pydantic schemas for validation
â”‚   â”œâ”€â”€ models/              # SQLAlchemy ORM models
â”‚   â”‚   â”œâ”€â”€ user.py          # User model with XP/level logic
â”‚   â”‚   â”œâ”€â”€ level.py         # Learning level model
â”‚   â”‚   â”œâ”€â”€ quest.py         # Quest model with evaluation config
â”‚   â”‚   â”œâ”€â”€ submission.py    # User submission tracking
â”‚   â”‚   â”œâ”€â”€ badge.py         # Badge/achievement model
â”‚   â”‚   â””â”€â”€ user_badge.py    # Many-to-many relationship
â”‚   â”œâ”€â”€ routes/              # API route handlers
â”‚   â”‚   â”œâ”€â”€ auth.py          # Authentication endpoints
â”‚   â”‚   â”œâ”€â”€ quests.py        # Quest management endpoints
â”‚   â”‚   â”œâ”€â”€ user.py          # User profile endpoints
â”‚   â”‚   â”œâ”€â”€ leaderboard.py   # Leaderboard endpoints
â”‚   â”‚   â””â”€â”€ dependencies.py  # Shared dependencies (auth middleware)
â”‚   â”œâ”€â”€ services/            # Business logic layer
â”‚   â”‚   â”œâ”€â”€ auth_service.py      # Authentication & JWT
â”‚   â”‚   â”œâ”€â”€ quest_service.py     # Quest management
â”‚   â”‚   â”œâ”€â”€ badge_service.py     # Badge awarding logic
â”‚   â”‚   â””â”€â”€ leaderboard_service.py # Ranking logic
â”‚   â””â”€â”€ ml_engine/           # ML evaluation engine
â”‚       â””â”€â”€ evaluator.py     # Generic model evaluation
â”œâ”€â”€ datasets/                # Training datasets
â”œâ”€â”€ uploads/                 # User-uploaded models
â”œâ”€â”€ sample_models/          # Pre-trained sample models
â”œâ”€â”€ init_db.py              # Database initialization script
â”œâ”€â”€ generate_datasets.py    # Dataset generation script
â”œâ”€â”€ train_sample_models.py  # Sample model training
â”œâ”€â”€ test_api.py             # API test suite
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ Dockerfile              # Docker container config
â”œâ”€â”€ docker-compose.yml      # Docker Compose config
â””â”€â”€ README.md               # This file
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- pip
- (Optional) Docker & Docker Compose

### Local Installation

1. **Clone the repository**
```bash
git clone <repository-url>
cd ml_game_platform
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Set up environment variables**
```bash
cp .env.example .env
# Edit .env and set SECRET_KEY
```

5. **Initialize database**
```bash
python init_db.py
```

6. **Generate sample datasets**
```bash
python generate_datasets.py
```

7. **Train sample models (optional)**
```bash
python train_sample_models.py
```

8. **Run the server**
```bash
uvicorn app.main:app --reload
```

9. **Access the API**
- API: http://localhost:8000
- Interactive Docs: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

10. **Run the Frontend (optional)**
```bash
cd frontend
npm install
npm run dev
```
- Frontend: http://localhost:5173

### Docker Installation

1. **Build and run with Docker Compose**
```bash
docker-compose up --build
```

2. **Access the API**
- API: http://localhost:8000
- Docs: http://localhost:8000/docs

## ğŸ“– Usage Guide

### 1. Register a User

```bash
curl -X POST "http://localhost:8000/auth/register" \
  -H "Content-Type: application/json" \
  -d '{
    "username": "alice",
    "email": "alice@example.com",
    "password": "securepass123"
  }'
```

### 2. Login

```bash
curl -X POST "http://localhost:8000/auth/login" \
  -H "Content-Type: application/json" \
  -d '{
    "username": "alice",
    "password": "securepass123"
  }'
```

Response:
```json
{
  "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "token_type": "bearer"
}
```

### 3. Get Available Quests

```bash
curl -X GET "http://localhost:8000/quests/" \
  -H "Authorization: Bearer YOUR_TOKEN"
```

### 4. Submit a Model for Evaluation

Train your model and save it:

```python
from sklearn.linear_model import LinearRegression
import pandas as pd
import joblib

# Load dataset
df = pd.read_csv('datasets/housing_train.csv')
X = df.drop(columns=['price'])
y = df['price']

# Train model
model = LinearRegression()
model.fit(X, y)

# Save model
joblib.dump(model, 'my_model.pkl')
```

Submit via API:

```bash
curl -X POST "http://localhost:8000/quests/1/submit" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -F "model_file=@my_model.pkl"
```

### 5. Check Your Progress

```bash
curl -X GET "http://localhost:8000/user/progress" \
  -H "Authorization: Bearer YOUR_TOKEN"
```

### 6. View Leaderboard

```bash
curl -X GET "http://localhost:8000/leaderboard/" \
  -H "Authorization: Bearer YOUR_TOKEN"
```

## ğŸ¯ Quest System

### Available Quests

#### Level 1: Regression Basics
- **Quest 1**: Linear Regression Challenge
  - Dataset: Housing prices
  - Metric: RÂ² score
  - Threshold: > 0.80
  - Reward: 100 XP

- **Quest 2**: Advanced Regression
  - Dataset: Housing prices
  - Metric: RÂ² score
  - Threshold: > 0.85
  - Reward: 150 XP

#### Level 2: Classification Mastery
- **Quest 3**: Binary Classification
  - Dataset: Customer churn
  - Metric: Accuracy
  - Threshold: > 0.85
  - Reward: 200 XP

- **Quest 4**: Multi-class Classification
  - Dataset: Iris species
  - Metric: F1-score
  - Threshold: > 0.90
  - Reward: 250 XP

#### Level 3: Advanced ML
- **Quest 5**: Advanced Classification Challenge
  - Dataset: Customer churn
  - Metric: Accuracy
  - Threshold: > 0.90
  - Reward: 300 XP

## ğŸ† Badge System

| Badge | Condition | Icon |
|-------|-----------|------|
| First Steps | Complete 1 quest | ğŸ¯ |
| Quest Master | Complete 5 quests | â­ |
| XP Hunter | Earn 500 XP | ğŸ’ |
| ML Expert | Earn 1500 XP | ğŸ† |
| Streak Champion | 7-day streak | ğŸ”¥ |
| Perfectionist | Perfect score on any quest | ğŸ’¯ |

## ğŸ§ª Testing

### Run Test Suite

```bash
# Make sure server is running
python test_api.py
```

### Run with pytest

```bash
pytest tests/
```

## ğŸ”§ Configuration

### Environment Variables

- `DATABASE_URL`: Database connection string (default: SQLite)
- `SECRET_KEY`: JWT secret key (must be 32+ characters)
- `HOST`: Server host (default: 0.0.0.0)
- `PORT`: Server port (default: 8000)

### Quest Configuration

Quests are configured in `init_db.py`. Each quest has:

- **task_type**: "regression", "classification", "clustering"
- **dataset_name**: CSV file in `datasets/` directory
- **metric_name**: "accuracy", "r2_score", "f1_score", etc.
- **threshold**: Minimum score to pass
- **config**: JSON with dataset-specific settings

Example:
```python
Quest(
    title="Linear Regression Challenge",
    task_type="regression",
    dataset_name="housing_train.csv",
    metric_name="r2_score",
    threshold=0.80,
    config={
        "target_column": "price",
        "test_size": 0.2,
        "random_state": 42
    }
)
```

## ğŸ”Œ API Reference

### Authentication

- `POST /auth/register` - Register new user
- `POST /auth/login` - Login and get JWT token

### Quests

- `GET /quests/` - List all quests with completion status
- `GET /quests/{id}` - Get quest details
- `POST /quests/{id}/submit` - Submit model for evaluation
- `GET /quests/{id}/submissions` - Get submission history

### User

- `GET /user/me` - Get current user profile
- `GET /user/progress` - Get detailed progress

### Leaderboard

- `GET /leaderboard/` - Get global rankings

## ğŸ§© Extending the Platform

### Adding New Quests

1. Add dataset to `datasets/`
2. Update `init_db.py` with new quest configuration
3. Run `python init_db.py` to update database

### Adding New Metrics

Edit `app/ml_engine/evaluator.py` and add to `_calculate_metric()`:

```python
def _calculate_metric(self, y_true, y_pred, metric_name: str) -> float:
    metric_functions = {
        "accuracy": accuracy_score,
        "r2_score": r2_score,
        # Add your custom metric here
        "my_custom_metric": my_custom_function,
    }
    # ...
```

### Adding New Badge Conditions

Edit `app/services/badge_service.py` and add to `_check_badge_condition()`:

```python
def _check_badge_condition(self, user_id: int, badge: Badge) -> bool:
    # Add new condition type
    if badge.condition_type == "my_new_condition":
        # Your logic here
        return True
    # ...
```

## ğŸ”’ Security

- âœ… Passwords hashed with bcrypt
- âœ… JWT token authentication
- âœ… Input validation with Pydantic
- âœ… SQL injection prevention (SQLAlchemy ORM)
- âœ… File upload validation

### Production Recommendations

1. Use PostgreSQL instead of SQLite
2. Set strong `SECRET_KEY` (32+ random characters)
3. Enable HTTPS
4. Configure CORS properly
5. Add rate limiting
6. Set up proper logging
7. Use environment-specific configs

## ğŸ“Š Database Schema

```sql
users
  - id, username, email, hashed_password
  - xp, level, current_streak, last_activity_date

levels
  - id, name, description, order, required_xp

quests
  - id, level_id, title, description, task_type
  - xp_reward, dataset_name, metric_name, threshold, config

submissions
  - id, user_id, quest_id, model_path
  - score, passed, xp_awarded, evaluation_logs

badges
  - id, name, description, icon
  - condition_type, condition_value

user_badges
  - id, user_id, badge_id, earned_at
```

## ğŸ› Troubleshooting

### Database Issues

```bash
# Reset database
rm ml_game_platform.db
python init_db.py
```

### Model Evaluation Fails

- Ensure model is saved in `.pkl` or `.joblib` format
- Check that feature names match dataset
- Verify model is trained on correct dataset

### Authentication Issues

- Check JWT token is included in Authorization header
- Verify token hasn't expired (7 days default)
- Ensure SECRET_KEY is set correctly

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“ License

MIT License - feel free to use for learning and commercial projects.

## ğŸ™ Acknowledgments

Built with:
- FastAPI - Modern web framework
- SQLAlchemy - SQL toolkit and ORM
- scikit-learn - Machine learning library
- Pydantic - Data validation

## ğŸ“ Support

For issues and questions:
- Open an issue on GitHub
- Check documentation at `/docs`
- Review test files for examples

---

**Happy Learning! ğŸ“ğŸ¤–**